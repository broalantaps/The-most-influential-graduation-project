#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆé…ç½®ç”Ÿæˆè„šæœ¬
ä½¿ç”¨çœŸå®çš„ Qwen3-0.6B å’Œ Qwen3-14B å®˜æ–¹é…ç½®å‚æ•°
"""

import json
import os
from typing import Dict, Any
from configuration_qwen_agentic import CompressorConfig, ConverterConfig, DecoderConfig

def load_qwen3_config(model_name: str) -> Dict[str, Any]:
    """
    åŠ è½½ Qwen3 æ¨¡å‹é…ç½®
    ä¼˜å…ˆä» HuggingFace åŠ è½½ï¼Œå¤±è´¥æ—¶ä½¿ç”¨é¢„å®šä¹‰é…ç½®
    """
    try:
        from transformers import AutoConfig
        if model_name == "Qwen/Qwen3-0.6B":
            config = CompressorConfig.from_pretrained(model_name)
        elif model_name == "Qwen/Qwen3-14B":
            config = DecoderConfig.from_pretrained(model_name)
        else:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹åç§°: {model_name}")
        print(f"ä» HuggingFace åŠ è½½ {model_name} æˆåŠŸ")
        config_dict = config.to_dict()
        # ç§»é™¤ä¸éœ€è¦çš„å­—æ®µ
        if "layer_types" in config_dict:
            del config_dict["layer_types"]
        return config_dict
    except ImportError:
        print(f"transformers åº“æœªå®‰è£…ï¼Œä½¿ç”¨ {model_name} çš„é¢„å®šä¹‰é…ç½®")
        return get_official_config(model_name)
    except Exception as e:
        print(f"ä» HuggingFace åŠ è½½ {model_name} é…ç½®å¤±è´¥: {e}")
        print(f"ä½¿ç”¨ {model_name} çš„é¢„å®šä¹‰é…ç½®")
        return get_official_config(model_name)


def get_official_config(model_name: str) -> Dict[str, Any]:
    """
    è·å–å®˜æ–¹é…ç½®ï¼ˆåŸºäºçœŸå®çš„ HuggingFace é…ç½®ï¼‰
    """
    if "0.6B" in model_name:
        # åŸºäºçœŸå®çš„ Qwen3-0.6B é…ç½®
        return {
            "model_type": "qwen3",
            "vocab_size": 151936,
            "max_position_embeddings": 40960,
            "hidden_size": 1024,
            "intermediate_size": 3072,
            "num_hidden_layers": 28,
            "num_attention_heads": 16,
            "use_sliding_window": False,
            "sliding_window": None,
            "max_window_layers": 28,
            "num_key_value_heads": 8,
            "head_dim": 128,
            "hidden_act": "silu",
            "initializer_range": 0.02,
            "rms_norm_eps": 1e-6,
            "use_cache": True,
            "rope_theta": 1000000,
            "rope_scaling": None,
            "attention_bias": False,
            "attention_dropout": 0.0,
            "tie_word_embeddings": True,
        }
    elif "14B" in model_name:
        # åŸºäºçœŸå®çš„ Qwen3-14B é…ç½®
        return {
            "model_type": "qwen3",
            "vocab_size": 151936,
            "max_position_embeddings": 40960,
            "hidden_size": 5120,
            "intermediate_size": 13696,
            "num_hidden_layers": 48,
            "num_attention_heads": 40,
            "use_sliding_window": False,
            "sliding_window": None,
            "max_window_layers": 28,
            "num_key_value_heads": 8,
            "head_dim": 128,
            "hidden_act": "silu",
            "initializer_range": 0.02,
            "rms_norm_eps": 1e-6,
            "use_cache": True,
            "rope_theta": 1000000,
            "rope_scaling": None,
            "attention_bias": False,
            "attention_dropout": 0.0,
            "tie_word_embeddings": True,
        }
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹åç§°: {model_name}")


def create_qwen3_agentic_config() -> Dict[str, Any]:
    """
    åˆ›å»º Qwen3Agentic é…ç½®
    åŸºäºçœŸå®çš„å®˜æ–¹æ¨¡å‹é…ç½®
    """
    print("æ­£åœ¨åŠ è½½ Qwen3-0.6B é…ç½®...")
    qwen3_0_6b_config = load_qwen3_config("Qwen/Qwen3-0.6B")
    
    print("æ­£åœ¨åŠ è½½ Qwen3-14B é…ç½®...")
    qwen3_14b_config = load_qwen3_config("Qwen/Qwen3-14B")
    
    # åˆ›å»ºè½¬æ¢å™¨é…ç½®
    converter_config = {
        "model_type": "converter",
        "architectures": [
            "Qwen3MLP"
        ],
        "input_hidden_size": qwen3_0_6b_config["hidden_size"],   # 1024
        "output_hidden_size": qwen3_14b_config["hidden_size"],   # 5120
        "intermediate_size": (qwen3_0_6b_config["hidden_size"] + qwen3_14b_config["hidden_size"]) // 2,  # 3072
        "hidden_act": qwen3_0_6b_config["hidden_act"],
        "rms_norm_eps": qwen3_0_6b_config["rms_norm_eps"],
    }
    
    # åˆ›å»ºä¸»é…ç½®
    main_config = {
        # åŸºæœ¬ä¿¡æ¯
        "model_type": "qwen3_agentic",
        "architectures": ["Qwen3Agentic"],
        # å­é…ç½®
        "compressor_config": {
            "base_model": "Qwen/Qwen3-0.6B",
            "model_type": "compressor",
            "architectures": [
                qwen3_0_6b_config['architectures'][0]
            ],
            "attention_bias": qwen3_0_6b_config["attention_bias"],
            "attention_dropout": qwen3_0_6b_config["attention_dropout"],
            "bos_token_id": qwen3_0_6b_config["bos_token_id"],
            "eos_token_id": qwen3_0_6b_config["eos_token_id"],
            "head_dim": qwen3_0_6b_config["head_dim"],
            "hidden_act": qwen3_0_6b_config["hidden_act"],
            "hidden_size": qwen3_0_6b_config["hidden_size"],
            "initializer_range": qwen3_0_6b_config["initializer_range"],
            "intermediate_size": qwen3_0_6b_config["intermediate_size"],
            "max_position_embeddings": qwen3_0_6b_config["max_position_embeddings"],
            "max_window_layers": qwen3_0_6b_config['max_window_layers'],
            "num_attention_heads": qwen3_0_6b_config["num_attention_heads"],
            "num_hidden_layers": qwen3_0_6b_config["num_hidden_layers"],
            "num_key_value_heads": qwen3_0_6b_config["num_key_value_heads"],
            "rms_norm_eps": qwen3_0_6b_config["rms_norm_eps"],
            "rope_scaling": qwen3_0_6b_config["rope_scaling"],
            "rope_theta": qwen3_0_6b_config["rope_theta"],
            "sliding_window": qwen3_0_6b_config["sliding_window"],
            "tie_word_embeddings": qwen3_0_6b_config["tie_word_embeddings"],
            "torch_dtype": qwen3_0_6b_config["dtype"],
            "transformers_version": "4.56.1",
            "use_cache": qwen3_0_6b_config["use_cache"],
            "use_sliding_window": qwen3_0_6b_config["use_sliding_window"],
            "vocab_size": qwen3_0_6b_config["vocab_size"],
            "max_segment_length": qwen3_0_6b_config["max_segment_length"],
            "mem_token_num": qwen3_0_6b_config["mem_token_num"],
        },
        
        "converter_config": converter_config,
        
        "decoder_config": {
            "model_type": "decoder",
            "base_model": "Qwen/Qwen3-14B",
            "architectures": [
                qwen3_14b_config['architectures'][0]
            ],
            "attention_bias": qwen3_14b_config["attention_bias"],
            "attention_dropout": qwen3_14b_config["attention_dropout"],
            "bos_token_id": qwen3_14b_config["bos_token_id"],
            "eos_token_id": qwen3_14b_config["eos_token_id"],
            "head_dim": qwen3_14b_config["head_dim"],
            "hidden_act": qwen3_14b_config["hidden_act"],
            "hidden_size": qwen3_14b_config["hidden_size"],
            "initializer_range": qwen3_14b_config["initializer_range"],
            "intermediate_size": qwen3_14b_config["intermediate_size"],
            "max_position_embeddings": qwen3_14b_config["max_position_embeddings"],
            "max_window_layers": qwen3_14b_config['max_window_layers'],
            "num_attention_heads": qwen3_14b_config["num_attention_heads"],
            "num_hidden_layers": qwen3_14b_config["num_hidden_layers"],
            "num_key_value_heads": qwen3_14b_config["num_key_value_heads"],
            "rms_norm_eps": qwen3_14b_config["rms_norm_eps"],
            "rope_scaling": qwen3_14b_config["rope_scaling"],
            "rope_theta": qwen3_14b_config["rope_theta"],
            "sliding_window": qwen3_14b_config["sliding_window"],
            "tie_word_embeddings": qwen3_14b_config["tie_word_embeddings"],
            "torch_dtype": qwen3_14b_config["dtype"],
            "transformers_version": "4.56.1",
            "use_cache": qwen3_14b_config["use_cache"],
            "use_sliding_window": qwen3_14b_config["use_sliding_window"],
            "vocab_size": qwen3_14b_config["vocab_size"],
        },
        
        # è‡ªåŠ¨æ˜ å°„
        "auto_map": {
            "AutoConfig": "configuration_qwen_agentic.Qwen3AgenticConfig",
            "AutoModel": "modeling_qwen_agentic.Qwen3Agentic",
            "AutoModelForCausalLM": "modeling_qwen_agentic.Qwen3Agentic"
        },
        
        # å…¶ä»–æ ‡å‡†å­—æ®µ
        "torch_dtype": "bfloat16",
        "transformers_version": "4.56.1"
    }
    
    return main_config


def save_config(config: Dict[str, Any], output_path: str = "config.json"):
    """ä¿å­˜é…ç½®åˆ° JSON æ–‡ä»¶"""
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else ".", exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… é…ç½®å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆ Qwen3 Agentic é…ç½®...")
    
    try:
        # åˆ›å»ºé…ç½®
        config = create_qwen3_agentic_config()
        
        # ä¿å­˜é…ç½®
        save_config(config, "config.json")
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        print("\n" + "="*60)
        print("ğŸ“‹ Qwen3 Agentic é…ç½®æ¦‚è§ˆ")
        print("="*60)
        
        print(f"ğŸ”§ æ¨¡å‹ç±»å‹: {config['model_type']}")
        print(f"ğŸ—ï¸  æ¶æ„: {config['architectures']}")
        
        
        print("\n" + "-"*40)
        print("ğŸ—œï¸  COMPRESSOR (åŸºäº Qwen3-0.6B)")
        print("-"*40)
        comp_config = config['compressor_config']
        print(f"   ğŸ“¦ åŸºç¡€æ¨¡å‹: {comp_config['base_model']}")
        print(f"   ğŸ§  Hidden Size: {comp_config['hidden_size']}")
        print(f"   ğŸ¢ Intermediate Size: {comp_config['intermediate_size']}")
        print(f"   ğŸ“š å±‚æ•°: {comp_config['num_hidden_layers']}")
        print(f"   ğŸ‘ï¸  æ³¨æ„åŠ›å¤´æ•°: {comp_config['num_attention_heads']}")
        print(f"   ğŸ”‘ KVå¤´æ•°: {comp_config['num_key_value_heads']}")
        
        print("\n" + "-"*40)
        print("ğŸ”„ CONVERTER (å°ºå¯¸è½¬æ¢å™¨)")
        print("-"*40)
        conv_config = config['converter_config']
        print(f"   ğŸ“¥ è¾“å…¥ç»´åº¦: {conv_config['input_hidden_size']} (æ¥è‡ª 0.6B)")
        print(f"   ğŸ“¤ è¾“å‡ºç»´åº¦: {conv_config['output_hidden_size']} (åˆ° 14B)")
        print(f"   âš™ï¸  ä¸­é—´å±‚å¤§å°: {conv_config['intermediate_size']}")
        
        print("\n" + "-"*40)
        print("ğŸ¯ DECODER (åŸºäº Qwen3-14B)")
        print("-"*40)
        dec_config = config['decoder_config']
        print(f"   ğŸ“¦ åŸºç¡€æ¨¡å‹: {dec_config['base_model']}")
        print(f"   ğŸ§  Hidden Size: {dec_config['hidden_size']}")
        print(f"   ğŸ¢ Intermediate Size: {dec_config['intermediate_size']}")
        print(f"   ğŸ“š å±‚æ•°: {dec_config['num_hidden_layers']}")
        print(f"   ğŸ‘ï¸  æ³¨æ„åŠ›å¤´æ•°: {dec_config['num_attention_heads']}")
        print(f"   ğŸ”‘ KVå¤´æ•°: {dec_config['num_key_value_heads']}")
        
        print("\n" + "-"*40)
        print("ğŸ›ï¸  è‡ªå®šä¹‰å‚æ•°")
        print("-"*40)
        # print(f"   ğŸ’¾ å†…å­˜æ®µé•¿åº¦: {config['max_segment_length']}")
        # print(f"   ğŸ« å†…å­˜tokenæ•°é‡: {config['mem_token_num']}")
        print(f"   ğŸ”¢ æ•°æ®ç±»å‹: {config['torch_dtype']}")
        
        print("\n" + "="*60)
        print("âœ¨ é…ç½®ç”Ÿæˆå®Œæˆï¼")
        print("="*60)
        
        return config
        
    except Exception as e:
        print(f"âŒ é…ç½®ç”Ÿæˆå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    config = main()
